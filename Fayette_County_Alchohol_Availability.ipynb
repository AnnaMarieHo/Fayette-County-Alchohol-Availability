{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21725a27-6b50-4eff-b7df-61c4ea745db8",
   "metadata": {},
   "source": [
    "## Alcohol availability in Fayette county’s neighborhoods\n",
    "\n",
    "This was an exploration aimed at using data from KY's Department of Alcoholic Beverage Control (ABC) to calculate the availability of alcohol in Fayette county’s neighborhoods\n",
    "\n",
    "I aimed to calculate the rate of liquor licenses per capita (the number of licenses divided by the neighborhood’s population).  I showed the top 20 neighborhoods with the highest rate of alcohol availability, as well as the top 20 neighborhoods with the highest number of licenses. Neighborhoods were defined as US Census Bureau tracts\n",
    "\n",
    "I utilized two files, downloaded from KY's ABC portal. (https://abc.ky.gov/) One contained all licenses, while the other contained a non-quota subset of licenses \n",
    "\n",
    "Population data was taken from the US Cencus Bureau with the hierarchy being country (largest) -> state -> county -> tract -> blockgroup -> block (smallest). I chose to calculate the rate at the cencus tract level  from the 2020 American Communities Survey using the US CEnsus Bureau's API (https://api.census.gov/data/2020/acs/acs5/profile?get=NAME,DP05_0001E&for=tract:*&in=state:21&in=county:067) \n",
    "\n",
    "Because the license counts were much smaller than the population counts, I adjusted the rate by multiplying by per 100 or 1000 people (so the rate is X licenses per 1000 people instead).\n",
    "\n",
    "Each license was associated with a street address, so I utilized geocoding to associate particular addresses with a cencus tract. An API call was made keeping in mind the rate limits. \n",
    "\n",
    "\n",
    "#### Parts 9 - 13 contain results \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d554355-f583-430a-a479-212aae88e583",
   "metadata": {},
   "source": [
    "## My Goals\n",
    "\n",
    "- For each neighborhood, calculate the rate of liquor licenses per capita (the number of licenses divided by the neighborhood’s population).  \n",
    "- Show the top 20 neighborhoods with the highest rate of alcohol availability. \n",
    "- Show the top 20 neighborhoods with the highest number of licenses.  \n",
    "- Calculate the rate at the census tract level; tracts typically average 4,000 people by design (with a range of 1,200 and 8,000 people)\n",
    "- Determine whether or not these two top-20 lists differ and how.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e641d28d-1be0-446c-840f-9151f2f6ef50",
   "metadata": {},
   "source": [
    "## Part 1: Test API call for census and geocoding data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "04d7573b-7d1a-45f0-9b3d-00c7817d5c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "response = requests.get(\"https://api.census.gov/data/2020/acs/acs5/profile?get=NAME,DP05_0001E&for=tract:*&in=state:21&in=county:067\")\n",
    "geocoding = requests.get(\" https://geocoding.geo.census.gov/geocoder/geographies/address?street=789+South+Limestone&city=Lexington&state=KY&benchmark=Public_AR_Census2020&vintage=Census2020_Census2020&layers=6&format=json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1627641f-6b0a-4f32-8ef0-4899a7abcd02",
   "metadata": {},
   "source": [
    "I've made a few simple print statements to test whether my API calls worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "bd7a2331-157a-41eb-bdca-b151b888201d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NAME', 'DP05_0001E', 'state', 'county', 'tract']\n",
      "{'city': 'Lexington', 'street': '789 South Limestone', 'state': 'KY'}\n"
     ]
    }
   ],
   "source": [
    "print(response.json()[0])\n",
    "print(geocoding.json()[\"result\"][\"input\"][\"address\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f741fb08-bda1-41ed-8c4e-9cff3637fda1",
   "metadata": {},
   "source": [
    "## Part 2: Census API response & Data Cleaning\n",
    "\n",
    "I first processed the census data from the API response and parsed it into a structured format for easier analysis. the JSON response is split into headers and data, which I used to create a pandas DataFrame. The NAME column, which contains location information, is split into three columns—\"Census Tract,\" \"County,\" and \"State\" to help me organize my approach. I inferred that the field DP05_0001E represents population totals, so I renamed to \"population\" for clarity. I standardized the column headers for \"state,\" \"county,\" and \"tract\" to uppercase to match corresponding fields in the geocoding JSON response. I rearragned the columns and placed \"Census Tract\" at the start for easier tracking. The original NAME column is retained as a final renaming to ensure compatibility with geocoding data. The processed census data is saved as a CSV file, \"census_output.csv,\" for future reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "60043e1e-46c1-46ea-ba58-218fe08d5c09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>population</th>\n",
       "      <th>STATE</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>TRACT</th>\n",
       "      <th>county_name</th>\n",
       "      <th>state_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Census Tract 1.01</td>\n",
       "      <td>3171</td>\n",
       "      <td>21</td>\n",
       "      <td>067</td>\n",
       "      <td>000101</td>\n",
       "      <td>Fayette County</td>\n",
       "      <td>Kentucky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Census Tract 1.02</td>\n",
       "      <td>1584</td>\n",
       "      <td>21</td>\n",
       "      <td>067</td>\n",
       "      <td>000102</td>\n",
       "      <td>Fayette County</td>\n",
       "      <td>Kentucky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Census Tract 2</td>\n",
       "      <td>3696</td>\n",
       "      <td>21</td>\n",
       "      <td>067</td>\n",
       "      <td>000200</td>\n",
       "      <td>Fayette County</td>\n",
       "      <td>Kentucky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Census Tract 3</td>\n",
       "      <td>2472</td>\n",
       "      <td>21</td>\n",
       "      <td>067</td>\n",
       "      <td>000300</td>\n",
       "      <td>Fayette County</td>\n",
       "      <td>Kentucky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Census Tract 4</td>\n",
       "      <td>1983</td>\n",
       "      <td>21</td>\n",
       "      <td>067</td>\n",
       "      <td>000400</td>\n",
       "      <td>Fayette County</td>\n",
       "      <td>Kentucky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Census Tract 42.07</td>\n",
       "      <td>3531</td>\n",
       "      <td>21</td>\n",
       "      <td>067</td>\n",
       "      <td>004207</td>\n",
       "      <td>Fayette County</td>\n",
       "      <td>Kentucky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Census Tract 42.08</td>\n",
       "      <td>7671</td>\n",
       "      <td>21</td>\n",
       "      <td>067</td>\n",
       "      <td>004208</td>\n",
       "      <td>Fayette County</td>\n",
       "      <td>Kentucky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Census Tract 42.09</td>\n",
       "      <td>4225</td>\n",
       "      <td>21</td>\n",
       "      <td>067</td>\n",
       "      <td>004209</td>\n",
       "      <td>Fayette County</td>\n",
       "      <td>Kentucky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Census Tract 42.10</td>\n",
       "      <td>5443</td>\n",
       "      <td>21</td>\n",
       "      <td>067</td>\n",
       "      <td>004210</td>\n",
       "      <td>Fayette County</td>\n",
       "      <td>Kentucky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Census Tract 39.14</td>\n",
       "      <td>2301</td>\n",
       "      <td>21</td>\n",
       "      <td>067</td>\n",
       "      <td>003914</td>\n",
       "      <td>Fayette County</td>\n",
       "      <td>Kentucky</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  NAME population STATE COUNTY   TRACT      county_name  \\\n",
       "0    Census Tract 1.01       3171    21    067  000101   Fayette County   \n",
       "1    Census Tract 1.02       1584    21    067  000102   Fayette County   \n",
       "2       Census Tract 2       3696    21    067  000200   Fayette County   \n",
       "3       Census Tract 3       2472    21    067  000300   Fayette County   \n",
       "4       Census Tract 4       1983    21    067  000400   Fayette County   \n",
       "..                 ...        ...   ...    ...     ...              ...   \n",
       "77  Census Tract 42.07       3531    21    067  004207   Fayette County   \n",
       "78  Census Tract 42.08       7671    21    067  004208   Fayette County   \n",
       "79  Census Tract 42.09       4225    21    067  004209   Fayette County   \n",
       "80  Census Tract 42.10       5443    21    067  004210   Fayette County   \n",
       "81  Census Tract 39.14       2301    21    067  003914   Fayette County   \n",
       "\n",
       "   state_name  \n",
       "0    Kentucky  \n",
       "1    Kentucky  \n",
       "2    Kentucky  \n",
       "3    Kentucky  \n",
       "4    Kentucky  \n",
       "..        ...  \n",
       "77   Kentucky  \n",
       "78   Kentucky  \n",
       "79   Kentucky  \n",
       "80   Kentucky  \n",
       "81   Kentucky  \n",
       "\n",
       "[82 rows x 7 columns]"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "# Capture the headers from the api response\n",
    "jsondata = response.json()[1:]\n",
    "# Capture the following rows from the api response\n",
    "columns = response.json()[0]\n",
    "\n",
    "# Convert the json data to a pandas dataframe\n",
    "census_data = pd.DataFrame(jsondata, columns=columns)\n",
    "\n",
    "# The NAME column is split into 3 columns, \"Cnensus Tract\", \"County\", and \"State\" (in hindsight this is not necessary but helped me organize my approach)\n",
    "census_data[['census_tract', 'county_name', 'state_name']] = census_data['NAME'].str.split(',', n=2, expand=True)\n",
    "# After looking at the Population totals for Fayette County’s census tracts, I inferred that DP05_0001E is representative of the tract's population. \n",
    "# For the sake of organization and consistency, I renamed state, county, and tract, as uppercase headers. This helped me quickly recognize that there\n",
    "# were corresponding fields in the geocoding json response\n",
    "census_data.rename(columns={'state': 'STATE', 'county': 'COUNTY', 'tract':'TRACT', 'DP05_0001E':'population'}, inplace=True)\n",
    "\n",
    "# I chose to reorganize the columns in a format that was easier for me to keep track of\n",
    "cols = census_data.columns.tolist()\n",
    "cols.insert(0, cols.pop(cols.index('census_tract')))\n",
    "cols.pop(cols.index('NAME'))\n",
    "\n",
    "census_data = census_data[cols]\n",
    "# I chose to keep the maintain the census_tract column as \"NAME\" to keep it consistent with the geocoding json response  \n",
    "census_data.rename(columns={'census_tract':'NAME'}, inplace=True)\n",
    "# The census responseis saved as a csv file for later reference and use\n",
    "census_data.to_csv('census_output.csv', index=False)\n",
    "census_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5007146d-840c-491f-9d09-a3183e0a0850",
   "metadata": {},
   "source": [
    "## Part 3: Import CSVs & Data Cleaning \n",
    "\n",
    "I cleaned and formatted the data from the provided CSV files containing active license information. I skipping the initial three rows of ActiveLicenses.csv to ensure correct formatting. The \"PremisesCityState\" column is split into \"premise,\" \"state,\" and \"zip\" fields. The \"PremisesStreet\" and \"City\" columns are renamed to \"street\" and \"city,\" respectively. Columns are reordered so that \"state\" and \"zip\" replace the original \"PremisesCityState\" position. I removed the redundant \"premise\" column as it was a duplicate of the \"street\" information. The cleaned data is saved as cleaned_licenses.csv.\n",
    "\n",
    "The same cleaning steps are applied to ActiveLicensesNQ.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "234c6a17-fd72-4f6e-8982-90cf1d993ca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SiteID</th>\n",
       "      <th>County</th>\n",
       "      <th>city</th>\n",
       "      <th>DBA</th>\n",
       "      <th>Licensee</th>\n",
       "      <th>street</th>\n",
       "      <th>state</th>\n",
       "      <th>zip</th>\n",
       "      <th>LicenseNumber</th>\n",
       "      <th>LicenseType</th>\n",
       "      <th>Status</th>\n",
       "      <th>IssueDate</th>\n",
       "      <th>EffectiveDate</th>\n",
       "      <th>ExpiryDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22790.0</td>\n",
       "      <td>Fayette</td>\n",
       "      <td>Lexington</td>\n",
       "      <td>21c Museum Hotel Lexington</td>\n",
       "      <td>167 MAIN HOTEL LLC</td>\n",
       "      <td>167 W Main St</td>\n",
       "      <td>KY</td>\n",
       "      <td>40507</td>\n",
       "      <td>034-CL-422</td>\n",
       "      <td>Caterer's License</td>\n",
       "      <td>Active</td>\n",
       "      <td>02/24/2016</td>\n",
       "      <td>02/24/2016</td>\n",
       "      <td>11/30/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22790.0</td>\n",
       "      <td>Fayette</td>\n",
       "      <td>Lexington</td>\n",
       "      <td>21c Museum Hotel Lexington</td>\n",
       "      <td>167 MAIN HOTEL LLC</td>\n",
       "      <td>167 W Main St</td>\n",
       "      <td>KY</td>\n",
       "      <td>40507</td>\n",
       "      <td>034-HI-29</td>\n",
       "      <td>Hotel In-Room License</td>\n",
       "      <td>Active</td>\n",
       "      <td>01/29/2016</td>\n",
       "      <td>01/29/2016</td>\n",
       "      <td>11/30/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22790.0</td>\n",
       "      <td>Fayette</td>\n",
       "      <td>Lexington</td>\n",
       "      <td>21c Museum Hotel Lexington</td>\n",
       "      <td>167 MAIN HOTEL LLC</td>\n",
       "      <td>167 W Main St</td>\n",
       "      <td>KY</td>\n",
       "      <td>40507</td>\n",
       "      <td>034-LP-2223</td>\n",
       "      <td>Quota Retail Package License</td>\n",
       "      <td>Active</td>\n",
       "      <td>04/29/2016</td>\n",
       "      <td>04/29/2016</td>\n",
       "      <td>11/30/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22790.0</td>\n",
       "      <td>Fayette</td>\n",
       "      <td>Lexington</td>\n",
       "      <td>21c Museum Hotel Lexington</td>\n",
       "      <td>167 MAIN HOTEL LLC</td>\n",
       "      <td>167 W Main St</td>\n",
       "      <td>KY</td>\n",
       "      <td>40507</td>\n",
       "      <td>034-NQ2-2920</td>\n",
       "      <td>NQ2 Retail Drink License</td>\n",
       "      <td>Active</td>\n",
       "      <td>01/29/2016</td>\n",
       "      <td>01/29/2016</td>\n",
       "      <td>11/30/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22790.0</td>\n",
       "      <td>Fayette</td>\n",
       "      <td>Lexington</td>\n",
       "      <td>21c Museum Hotel Lexington</td>\n",
       "      <td>167 MAIN HOTEL LLC</td>\n",
       "      <td>167 W Main St</td>\n",
       "      <td>KY</td>\n",
       "      <td>40507</td>\n",
       "      <td>034-RS-4300</td>\n",
       "      <td>Special Sunday Retail Drink License</td>\n",
       "      <td>Active</td>\n",
       "      <td>01/29/2016</td>\n",
       "      <td>01/29/2016</td>\n",
       "      <td>11/30/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1847</th>\n",
       "      <td>27204.0</td>\n",
       "      <td>Fayette</td>\n",
       "      <td>Lexington</td>\n",
       "      <td>Zim's Cafe</td>\n",
       "      <td>Zim's Cafe , LLC</td>\n",
       "      <td>215 W. Main Street</td>\n",
       "      <td>KY</td>\n",
       "      <td>40507</td>\n",
       "      <td>034-NQ2-3843</td>\n",
       "      <td>NQ2 Retail Drink License</td>\n",
       "      <td>Active</td>\n",
       "      <td>11/15/2018</td>\n",
       "      <td>11/15/2018</td>\n",
       "      <td>11/30/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1848</th>\n",
       "      <td>27204.0</td>\n",
       "      <td>Fayette</td>\n",
       "      <td>Lexington</td>\n",
       "      <td>Zim's Cafe</td>\n",
       "      <td>Zim's Cafe , LLC</td>\n",
       "      <td>215 W. Main Street</td>\n",
       "      <td>KY</td>\n",
       "      <td>40507</td>\n",
       "      <td>034-RS-5498</td>\n",
       "      <td>Special Sunday Retail Drink License</td>\n",
       "      <td>Active</td>\n",
       "      <td>11/15/2018</td>\n",
       "      <td>11/15/2018</td>\n",
       "      <td>11/30/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1849</th>\n",
       "      <td>27204.0</td>\n",
       "      <td>Fayette</td>\n",
       "      <td>Lexington</td>\n",
       "      <td>Zim's Cafe</td>\n",
       "      <td>Zim's Cafe , LLC</td>\n",
       "      <td>215 W. Main Street</td>\n",
       "      <td>KY</td>\n",
       "      <td>40507</td>\n",
       "      <td>034-SP-196439</td>\n",
       "      <td>Sampling License</td>\n",
       "      <td>Active</td>\n",
       "      <td>04/25/2023</td>\n",
       "      <td>04/25/2023</td>\n",
       "      <td>11/30/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1850</th>\n",
       "      <td>35579.0</td>\n",
       "      <td>Fayette</td>\n",
       "      <td>Lexington</td>\n",
       "      <td>Zundo</td>\n",
       "      <td>ZUNDO RAMEN AND POKE LLC</td>\n",
       "      <td>127 W Tiverton Way</td>\n",
       "      <td>KY</td>\n",
       "      <td>40503</td>\n",
       "      <td>034-NQ2-193247</td>\n",
       "      <td>NQ2 Retail Drink License</td>\n",
       "      <td>Active</td>\n",
       "      <td>10/13/2022</td>\n",
       "      <td>10/13/2022</td>\n",
       "      <td>11/30/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1851</th>\n",
       "      <td>35579.0</td>\n",
       "      <td>Fayette</td>\n",
       "      <td>Lexington</td>\n",
       "      <td>Zundo</td>\n",
       "      <td>ZUNDO RAMEN AND POKE LLC</td>\n",
       "      <td>127 W Tiverton Way</td>\n",
       "      <td>KY</td>\n",
       "      <td>40503</td>\n",
       "      <td>034-RS-193248</td>\n",
       "      <td>Special Sunday Retail Drink License</td>\n",
       "      <td>Active</td>\n",
       "      <td>10/13/2022</td>\n",
       "      <td>10/13/2022</td>\n",
       "      <td>11/30/2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1852 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SiteID   County       city                         DBA  \\\n",
       "0     22790.0  Fayette  Lexington  21c Museum Hotel Lexington   \n",
       "1     22790.0  Fayette  Lexington  21c Museum Hotel Lexington   \n",
       "2     22790.0  Fayette  Lexington  21c Museum Hotel Lexington   \n",
       "3     22790.0  Fayette  Lexington  21c Museum Hotel Lexington   \n",
       "4     22790.0  Fayette  Lexington  21c Museum Hotel Lexington   \n",
       "...       ...      ...        ...                         ...   \n",
       "1847  27204.0  Fayette  Lexington                  Zim's Cafe   \n",
       "1848  27204.0  Fayette  Lexington                  Zim's Cafe   \n",
       "1849  27204.0  Fayette  Lexington                  Zim's Cafe   \n",
       "1850  35579.0  Fayette  Lexington                       Zundo   \n",
       "1851  35579.0  Fayette  Lexington                       Zundo   \n",
       "\n",
       "                       Licensee              street state    zip  \\\n",
       "0           167 MAIN HOTEL LLC        167 W Main St    KY  40507   \n",
       "1           167 MAIN HOTEL LLC        167 W Main St    KY  40507   \n",
       "2           167 MAIN HOTEL LLC        167 W Main St    KY  40507   \n",
       "3           167 MAIN HOTEL LLC        167 W Main St    KY  40507   \n",
       "4           167 MAIN HOTEL LLC        167 W Main St    KY  40507   \n",
       "...                         ...                 ...   ...    ...   \n",
       "1847          Zim's Cafe , LLC   215 W. Main Street    KY  40507   \n",
       "1848          Zim's Cafe , LLC   215 W. Main Street    KY  40507   \n",
       "1849          Zim's Cafe , LLC   215 W. Main Street    KY  40507   \n",
       "1850  ZUNDO RAMEN AND POKE LLC   127 W Tiverton Way    KY  40503   \n",
       "1851  ZUNDO RAMEN AND POKE LLC   127 W Tiverton Way    KY  40503   \n",
       "\n",
       "       LicenseNumber                          LicenseType  Status   IssueDate  \\\n",
       "0         034-CL-422                    Caterer's License  Active  02/24/2016   \n",
       "1          034-HI-29                Hotel In-Room License  Active  01/29/2016   \n",
       "2        034-LP-2223         Quota Retail Package License  Active  04/29/2016   \n",
       "3       034-NQ2-2920             NQ2 Retail Drink License  Active  01/29/2016   \n",
       "4        034-RS-4300  Special Sunday Retail Drink License  Active  01/29/2016   \n",
       "...              ...                                  ...     ...         ...   \n",
       "1847    034-NQ2-3843             NQ2 Retail Drink License  Active  11/15/2018   \n",
       "1848     034-RS-5498  Special Sunday Retail Drink License  Active  11/15/2018   \n",
       "1849   034-SP-196439                     Sampling License  Active  04/25/2023   \n",
       "1850  034-NQ2-193247             NQ2 Retail Drink License  Active  10/13/2022   \n",
       "1851   034-RS-193248  Special Sunday Retail Drink License  Active  10/13/2022   \n",
       "\n",
       "     EffectiveDate  ExpiryDate  \n",
       "0       02/24/2016  11/30/2023  \n",
       "1       01/29/2016  11/30/2023  \n",
       "2       04/29/2016  11/30/2023  \n",
       "3       01/29/2016  11/30/2023  \n",
       "4       01/29/2016  11/30/2023  \n",
       "...            ...         ...  \n",
       "1847    11/15/2018  11/30/2023  \n",
       "1848    11/15/2018  11/30/2023  \n",
       "1849    04/25/2023  11/30/2023  \n",
       "1850    10/13/2022  11/30/2023  \n",
       "1851    10/13/2022  11/30/2023  \n",
       "\n",
       "[1852 rows x 14 columns]"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# I saved the active licenses to a csv file, and skipped the first 3 rows, as their inclusion disrupted the formatting \n",
    "active_licenses = pd.read_csv('ActiveLicenses.csv', skiprows=3, encoding='utf-8')\n",
    "# separated the \"Premise/City/State\" column into separate fields\n",
    "active_licenses[['premise', 'state', 'zip']] = active_licenses['PremisesCityState'].str.split(' ', n=2, expand=True)\n",
    "# I converted the \"PremisesStreet\" and city to shorter lowercase names \n",
    "active_licenses.rename(columns={'PremisesStreet':'street', 'City':'city'}, inplace=True)\n",
    "\n",
    "# I reordered the columns so that the separated columns would take the place of the \"PremiseCityState\" columns\n",
    "cols = active_licenses.columns.tolist()\n",
    "premises_idx = cols.index('PremisesCityState')\n",
    "cols.insert(premises_idx + 1, cols.pop(cols.index('state')))\n",
    "cols.insert(premises_idx + 2, cols.pop(cols.index('zip')))\n",
    "cols.pop(cols.index('PremisesCityState'))\n",
    "\n",
    "# Since the premise contains the same information as the \"street\" column (formerly \"PremisesStreet\" column), I removed the duplicate column\n",
    "cols.pop(cols.index('premise'))\n",
    "active_licenses = active_licenses[cols]\n",
    "\n",
    "# The cleaned and reformatted licenses dataset is saved to a csv file for later use and reference\n",
    "active_licenses.to_csv('cleaned_licenses.csv', index=False)\n",
    "\n",
    "#The same cleaning process is applied to the Active LicenseNQ dataset\n",
    "active_licensesNQ = pd.read_csv('ActiveLicensesNQ.csv', skiprows=3, encoding='utf-8')\n",
    "active_licensesNQ[['premise', 'state', 'zip']] = active_licensesNQ['PremisesCityState'].str.split(' ', n=2, expand=True)\n",
    "active_licensesNQ.rename(columns={'PremisesStreet':'street', 'City':'city'}, inplace=True)\n",
    "cols = active_licensesNQ.columns.tolist()\n",
    "premises_idx = cols.index('PremisesCityState')\n",
    "cols.insert(premises_idx + 1, cols.pop(cols.index('state')))\n",
    "cols.insert(premises_idx + 2, cols.pop(cols.index('zip')))\n",
    "cols.pop(cols.index('PremisesCityState'))\n",
    "cols.pop(cols.index('premise'))\n",
    "\n",
    "active_licensesNQ = active_licenses[cols]\n",
    "# The cleaned and reformatted non-quota licenses dataset is saved to a csv file for later use and reference\n",
    "active_licensesNQ.to_csv('cleaned_licensesNQ.csv', index=False)\n",
    "active_licenses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "f5295544-8d00-44ac-a4c4-a997e503b5f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Census Tract 38.02'"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A geocoding test that I frequently referenced as I was verifying fields across datasets\n",
    "test = requests.get(\" https://geocoding.geo.census.gov/geocoder/geographies/address?street=4089+Iron+Works+Pkwy&city=Lexington&state=KY&benchmark=Public_AR_Census2020&vintage=Census2020_Census2020&layers=6&format=json\")\n",
    "test.json()['result']['addressMatches'][0]['geographies']\n",
    "test_tract = test.json()['result']['addressMatches'][0]['geographies']['Census Tracts'][0]['NAME']\n",
    "test_tract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b39c55c-b9dd-4996-a2fd-b8453a86ae93",
   "metadata": {},
   "source": [
    "## Part 4: Check for missing SiteIDs\n",
    "\n",
    "Missing site IDs are identified and grouped by street. The number of missing `SiteID` values (`NaN`s) is calculated for each street. A dataframe is displayed and defined to visualize missing counts by street. Only streets with at least one missing `SiteID` are shown in the filtered output, `nan_count_filtered`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "1ee4a6b8-11cf-47e0-b62e-ea31e16b08fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>street</th>\n",
       "      <th>nan_SiteID_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>125 Barr St</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>1685 Jaggie Fox Way</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>215 W Main St Ste 250</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>2339 Sandersville Rd</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>251 W Main St</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>251 W Second St</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>3333 Bowman Mill Rd</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>3415 Entertainment Ct</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>4089 Iron Works Pkwy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>430 West Vine St</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>601 Hill N Dale Rd</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    street  nan_SiteID_count\n",
       "113            125 Barr St                 1\n",
       "222    1685 Jaggie Fox Way                 1\n",
       "325  215 W Main St Ste 250                 3\n",
       "374   2339 Sandersville Rd                 1\n",
       "404          251 W Main St                 2\n",
       "405        251 W Second St                 1\n",
       "512    3333 Bowman Mill Rd                 1\n",
       "531  3415 Entertainment Ct                 1\n",
       "630   4089 Iron Works Pkwy                 1\n",
       "651       430 West Vine St                 1\n",
       "730     601 Hill N Dale Rd                 2"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Since the geocoding API response requires a unique ID, I assumed that SiteID would be requried. \n",
    "# Therefore, I counted the number of missing IDs and grouped them by their corresponding street.\n",
    "nan_count = active_licenses.groupby('street')['SiteID'].apply(lambda x: x.isna().sum()).reset_index()\n",
    "# I created a dataframe to display these nan values and visually see what streets are missing SiteIDs\n",
    "nan_count.columns = ['street', 'nan_SiteID_count']\n",
    "# Only nan values with occurences greater than 0 are displayed \n",
    "nan_count_filtered = nan_count[nan_count['nan_SiteID_count'] > 0]\n",
    "\n",
    "nan_count_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc2f021-29bb-44a7-b41d-67110bff2b74",
   "metadata": {},
   "source": [
    "### Determine if an address has non-NaN SiteIDs \n",
    "\n",
    "I created a function to check for missing (`NaN`) and non-missing (`non-NaN`) `SiteID` values for each street in the `active_licenses` dataset. It reads the `cleaned_licenses.csv` file to display the `SiteID` status for each street. The number of missing `SiteID`s per street are stored in a DataFrame (`nan_count`). The non-missing values (`non-NaN`) are counted per street, and stored in another DataFrame (`not_nan_count`). Both DataFrames are merged to allow for a side-by-side view of missing vs. non-missing `SiteID` values by street. The function returns only streets with missing `SiteID`s, providing a both `NaN` and non-`NaN` counts for those streets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "ff790971-eec3-4149-8e39-bdbc05fd92b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>street</th>\n",
       "      <th>nan_SiteID_count</th>\n",
       "      <th>not_nan_SiteID_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>125 Barr St</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>1685 Jaggie Fox Way</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>215 W Main St Ste 250</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>2339 Sandersville Rd</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>251 W Main St</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>251 W Second St</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>3333 Bowman Mill Rd</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>3415 Entertainment Ct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>4089 Iron Works Pkwy</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>430 West Vine St</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>601 Hill N Dale Rd</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    street  nan_SiteID_count  not_nan_SiteID_count\n",
       "113            125 Barr St                 1                     0\n",
       "222    1685 Jaggie Fox Way                 1                     0\n",
       "325  215 W Main St Ste 250                 3                     0\n",
       "374   2339 Sandersville Rd                 1                     0\n",
       "404          251 W Main St                 2                     0\n",
       "405        251 W Second St                 1                     0\n",
       "512    3333 Bowman Mill Rd                 1                     0\n",
       "531  3415 Entertainment Ct                 1                     0\n",
       "630   4089 Iron Works Pkwy                 1                     1\n",
       "651       430 West Vine St                 1                     0\n",
       "730     601 Hill N Dale Rd                 2                     0"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# To determine if there were existing site IDs I could use, I captured the number of nan and non-nan values for each address\n",
    "active_licenses = pd.read_csv('cleaned_licenses.csv', encoding='utf-8')\n",
    "\n",
    "# A function for checking a streets nan values and corresponding non-nan values \n",
    "def check_nan_values(active_licenses):\n",
    "    # The number of nan Site IDs is counted \n",
    "    nan_count = active_licenses.groupby('street')['SiteID'].apply(lambda x: x.isna().sum()).reset_index()\n",
    "    nan_count.columns = ['street', 'nan_SiteID_count']\n",
    "    \n",
    "    # The number of non-nan Site IDs is counted\n",
    "    not_nan_count = active_licenses.groupby('street')['SiteID'].apply(lambda x: x.notna().sum()).reset_index()\n",
    "    not_nan_count.columns = ['street', 'not_nan_SiteID_count']\n",
    "    \n",
    "    # To visually see the nan vs non-nan occurences for each affected street, I merged the dataframes \n",
    "    count_summary = pd.merge(nan_count, not_nan_count, on='street')\n",
    "    \n",
    "    # Only the streets with nan values are displayed, resulting in a way to see both nan and non-nan values per street\n",
    "    nan_count_filtered = count_summary[count_summary['nan_SiteID_count'] > 0]\n",
    "    return nan_count_filtered\n",
    "\n",
    "check_nan_values(active_licenses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f20b8e7-b9b6-4eb7-9f94-c74cf14a2da7",
   "metadata": {},
   "source": [
    "### Replace missing SiteIDs\n",
    "\n",
    "Unique IDs are assigned to missing `SiteID` values in the `active_licenses` dataset. If any street has both missing and existing IDs, the existing ID is used for all entries. A `generate_unique_id` function produces random IDs for streets with no existing `SiteID`s. Duplicates are avoided by checking against a list of `unique_ids`, which stores all IDs in use.\n",
    "\n",
    "The code iterates over each street in the dataset. A unique ID is generated and assigned to all missing entries for for a particular street. For streets with existing `SiteID`s, the first non-missing ID found is used to fill any missing values. The updated DataFrame is saved to `active_licenses_IDs.csv`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "10f74680-c04b-417b-bf31-06ebf68495fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>street</th>\n",
       "      <th>nan_SiteID_count</th>\n",
       "      <th>not_nan_SiteID_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [street, nan_SiteID_count, not_nan_SiteID_count]\n",
       "Index: []"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# IDs are assigned to missing SiteID fields, while any street that has more than one entry with both missing and existing values \n",
    "# will be automatically assigned the existing SiteID\n",
    "\n",
    "random.seed(43)\n",
    "\n",
    "# Whenever an ID is found to be missing, this function will be called to generate a random ID that is not already in unique_ids\n",
    "def generate_unique_id(existing_ids):\n",
    "    while True:\n",
    "        new_id = random.randint(1000, 99999) \n",
    "        if new_id not in existing_ids:\n",
    "            return new_id\n",
    "\n",
    "# A list is initialized to contain all unique IDs in the dataset\n",
    "unique_ids = active_licenses['SiteID'].dropna().unique().tolist()\n",
    "\n",
    "# A dictionary us initialized to store the assigned SiteID for each street with nan values\n",
    "street_ids = {}\n",
    "\n",
    "# each street in the dataset is iterated over\n",
    "for street in active_licenses['street']:\n",
    "    # If there are any non-nan values for the current street, they will be stored in a variable called \"non_nan_values\" \n",
    "    non_nan_values = active_licenses.loc[active_licenses['street'] == street, 'SiteID'].dropna().unique()\n",
    "    \n",
    "    # If there are no non-nan values, nan values will be replaced with a randomly generated ID\n",
    "    if non_nan_values.size == 0:\n",
    "        # all nan IDs for the current street will be stored in a variable called \"nan_indices\"\n",
    "        nan_indices = active_licenses.index[(active_licenses['street'] == street) & (active_licenses['SiteID'].isna())]\n",
    "\n",
    "        # If an ID has not already been assigned to the current street, the \"generate_unique_id\" function will be called\n",
    "        if street not in street_ids:\n",
    "            street_ids[street] = generate_unique_id(unique_ids)\n",
    "            # The new ID will be added to the unique_ids list\n",
    "            unique_ids.append(street_ids[street]) \n",
    "            \n",
    "        # The stored ID is assigned to each nan SiteID for the current street\n",
    "        for index in nan_indices:\n",
    "            active_licenses.at[index, 'SiteID'] = street_ids[street]\n",
    "\n",
    "    else:\n",
    "        # If there are non-nan values for a street, the first non-nan value is used to replace the nan value\n",
    "        replacement_value = non_nan_values[0]\n",
    "        active_licenses.loc[(active_licenses['street'] == street) & (active_licenses['SiteID'].isna()), 'SiteID'] = replacement_value\n",
    "\n",
    "\n",
    "# Save the updated DataFrame to a CSV file\n",
    "active_licenses.to_csv(\"active_licenses_IDs.csv\", index=False)\n",
    "\n",
    "\n",
    "# verification to check if the updated dataset still contains null IDs\n",
    "check_nan_values(active_licenses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc97613-4472-4b87-9b03-4c1f40ac9245",
   "metadata": {},
   "source": [
    "### verify that generated IDs are consistent for each instance of a street"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "322ecf18-bded-4d1a-845b-f4e07d7539a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SiteID</th>\n",
       "      <th>County</th>\n",
       "      <th>city</th>\n",
       "      <th>DBA</th>\n",
       "      <th>Licensee</th>\n",
       "      <th>street</th>\n",
       "      <th>state</th>\n",
       "      <th>zip</th>\n",
       "      <th>LicenseNumber</th>\n",
       "      <th>LicenseType</th>\n",
       "      <th>Status</th>\n",
       "      <th>IssueDate</th>\n",
       "      <th>EffectiveDate</th>\n",
       "      <th>ExpiryDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>19865.0</td>\n",
       "      <td>Fayette</td>\n",
       "      <td>Lexington</td>\n",
       "      <td>December 2023</td>\n",
       "      <td>BREEDERS' CUP LIMITED</td>\n",
       "      <td>215 W Main St Ste 250</td>\n",
       "      <td>KY</td>\n",
       "      <td>40507</td>\n",
       "      <td>034-TA-196406</td>\n",
       "      <td>Special Temporary Alcoholic Beverage Auction L...</td>\n",
       "      <td>Active</td>\n",
       "      <td>04/24/2023</td>\n",
       "      <td>12/01/2023</td>\n",
       "      <td>12/30/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1143</th>\n",
       "      <td>19865.0</td>\n",
       "      <td>Fayette</td>\n",
       "      <td>Lexington</td>\n",
       "      <td>November 2023</td>\n",
       "      <td>BREEDERS' CUP LIMITED</td>\n",
       "      <td>215 W Main St Ste 250</td>\n",
       "      <td>KY</td>\n",
       "      <td>40507</td>\n",
       "      <td>034-TA-196405</td>\n",
       "      <td>Special Temporary Alcoholic Beverage Auction L...</td>\n",
       "      <td>Active</td>\n",
       "      <td>04/24/2023</td>\n",
       "      <td>11/01/2023</td>\n",
       "      <td>11/30/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1151</th>\n",
       "      <td>19865.0</td>\n",
       "      <td>Fayette</td>\n",
       "      <td>Lexington</td>\n",
       "      <td>October 2023</td>\n",
       "      <td>BREEDERS' CUP LIMITED</td>\n",
       "      <td>215 W Main St Ste 250</td>\n",
       "      <td>KY</td>\n",
       "      <td>40507</td>\n",
       "      <td>034-TA-196404</td>\n",
       "      <td>Special Temporary Alcoholic Beverage Auction L...</td>\n",
       "      <td>Active</td>\n",
       "      <td>04/24/2023</td>\n",
       "      <td>10/01/2023</td>\n",
       "      <td>10/30/2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       SiteID   County       city            DBA                 Licensee  \\\n",
       "418   19865.0  Fayette  Lexington  December 2023  BREEDERS' CUP LIMITED     \n",
       "1143  19865.0  Fayette  Lexington  November 2023  BREEDERS' CUP LIMITED     \n",
       "1151  19865.0  Fayette  Lexington   October 2023  BREEDERS' CUP LIMITED     \n",
       "\n",
       "                     street state    zip  LicenseNumber  \\\n",
       "418   215 W Main St Ste 250    KY  40507  034-TA-196406   \n",
       "1143  215 W Main St Ste 250    KY  40507  034-TA-196405   \n",
       "1151  215 W Main St Ste 250    KY  40507  034-TA-196404   \n",
       "\n",
       "                                            LicenseType  Status   IssueDate  \\\n",
       "418   Special Temporary Alcoholic Beverage Auction L...  Active  04/24/2023   \n",
       "1143  Special Temporary Alcoholic Beverage Auction L...  Active  04/24/2023   \n",
       "1151  Special Temporary Alcoholic Beverage Auction L...  Active  04/24/2023   \n",
       "\n",
       "     EffectiveDate  ExpiryDate  \n",
       "418     12/01/2023  12/30/2023  \n",
       "1143    11/01/2023  11/30/2023  \n",
       "1151    10/01/2023  10/30/2023  "
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify that generated IDs are consistent for each instance of a street\n",
    "active_licenses.loc[active_licenses['street'].str.contains('215 W Main St Ste 250', na=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fd65f1-e2f3-404c-b086-10644817040a",
   "metadata": {},
   "source": [
    "### verify that NaN values for a street, are replaced by non-NaN values found in other instances of the street"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "48ea1d7d-ec96-4483-b6be-038ea521a48b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SiteID</th>\n",
       "      <th>County</th>\n",
       "      <th>city</th>\n",
       "      <th>DBA</th>\n",
       "      <th>Licensee</th>\n",
       "      <th>street</th>\n",
       "      <th>state</th>\n",
       "      <th>zip</th>\n",
       "      <th>LicenseNumber</th>\n",
       "      <th>LicenseType</th>\n",
       "      <th>Status</th>\n",
       "      <th>IssueDate</th>\n",
       "      <th>EffectiveDate</th>\n",
       "      <th>ExpiryDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>18700.0</td>\n",
       "      <td>Fayette</td>\n",
       "      <td>Lexington</td>\n",
       "      <td>Adult Comedy Night Fundraiser</td>\n",
       "      <td>UNEXPECTED BLESSINGS FOUNDATION, INC.</td>\n",
       "      <td>4089 Iron Works Pkwy</td>\n",
       "      <td>KY</td>\n",
       "      <td>40511</td>\n",
       "      <td>034-TL-199387</td>\n",
       "      <td>Special Temporary License</td>\n",
       "      <td>Active</td>\n",
       "      <td>10/03/2023</td>\n",
       "      <td>10/20/2023</td>\n",
       "      <td>10/20/2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>18700.0</td>\n",
       "      <td>Fayette</td>\n",
       "      <td>Lexington</td>\n",
       "      <td>Kentucky Horse Park</td>\n",
       "      <td>KENTUCKY HORSE PARK</td>\n",
       "      <td>4089 Iron Works Pkwy</td>\n",
       "      <td>KY</td>\n",
       "      <td>40511</td>\n",
       "      <td>034-LP-186334</td>\n",
       "      <td>Quota Retail Package License</td>\n",
       "      <td>Active</td>\n",
       "      <td>09/17/2021</td>\n",
       "      <td>09/17/2021</td>\n",
       "      <td>11/30/2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      SiteID   County       city                            DBA  \\\n",
       "13   18700.0  Fayette  Lexington  Adult Comedy Night Fundraiser   \n",
       "816  18700.0  Fayette  Lexington            Kentucky Horse Park   \n",
       "\n",
       "                                   Licensee                street state  \\\n",
       "13   UNEXPECTED BLESSINGS FOUNDATION, INC.   4089 Iron Works Pkwy    KY   \n",
       "816                     KENTUCKY HORSE PARK  4089 Iron Works Pkwy    KY   \n",
       "\n",
       "       zip  LicenseNumber                   LicenseType  Status   IssueDate  \\\n",
       "13   40511  034-TL-199387     Special Temporary License  Active  10/03/2023   \n",
       "816  40511  034-LP-186334  Quota Retail Package License  Active  09/17/2021   \n",
       "\n",
       "    EffectiveDate  ExpiryDate  \n",
       "13     10/20/2023  10/20/2023  \n",
       "816    09/17/2021  11/30/2023  "
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# verify that non-nan values for a street, are replaced by the first non-nan value found for other instances of a street\n",
    "active_licenses.loc[active_licenses['street'].str.contains('4089 Iron Works Pkwy', na=False)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488d7cbd-b3a8-46ca-a50b-78812d1f0c62",
   "metadata": {},
   "source": [
    "## Part 6: Save addresses in batch compatible format\n",
    "\n",
    "Address data is prepared for a batch API request by creating a CSV file with the required columns: Unique ID (`SiteID`), street address, city, state, and ZIP code. Columns from the `active_licenses` DataFrame are selected and ordered with the necessary formatting to ensure a successful API submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "c502978f-1735-4f71-9936-d212001fefd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Addresses saved successfully.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SiteID</th>\n",
       "      <th>street</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22790.0</td>\n",
       "      <td>167 W Main St</td>\n",
       "      <td>Lexington</td>\n",
       "      <td>KY</td>\n",
       "      <td>40507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22790.0</td>\n",
       "      <td>167 W Main St</td>\n",
       "      <td>Lexington</td>\n",
       "      <td>KY</td>\n",
       "      <td>40507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22790.0</td>\n",
       "      <td>167 W Main St</td>\n",
       "      <td>Lexington</td>\n",
       "      <td>KY</td>\n",
       "      <td>40507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22790.0</td>\n",
       "      <td>167 W Main St</td>\n",
       "      <td>Lexington</td>\n",
       "      <td>KY</td>\n",
       "      <td>40507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22790.0</td>\n",
       "      <td>167 W Main St</td>\n",
       "      <td>Lexington</td>\n",
       "      <td>KY</td>\n",
       "      <td>40507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SiteID         street       city state    zip\n",
       "0  22790.0  167 W Main St  Lexington    KY  40507\n",
       "1  22790.0  167 W Main St  Lexington    KY  40507\n",
       "2  22790.0  167 W Main St  Lexington    KY  40507\n",
       "3  22790.0  167 W Main St  Lexington    KY  40507\n",
       "4  22790.0  167 W Main St  Lexington    KY  40507"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# A batch API request requires a CSV format where columns are:Unique ID, Street address, City, State, ZIP\n",
    "# Therefore, I created a dataframe composed of the appropriate columns, and wrote the addresses to a csv file for submission in a batch API request\n",
    "\n",
    "selected_columns = active_licenses[['SiteID', 'street', 'city', 'state', 'zip']]\n",
    "selected_columns.to_csv('addresses.csv', index=False,  quoting=1)\n",
    "\n",
    "print(\"Addresses saved successfully.\")\n",
    "selected_columns.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9d9b25-184e-46d5-afe2-d5fce7f0d41f",
   "metadata": {},
   "source": [
    "## Part 7: Submit API request\n",
    "\n",
    "`curl` is used to handle the API submission. It posts the `addresses.csv` file to the geocoding API, using parameters `benchmark=4` and `vintage=4` for specific data settings, and outputs the result to `all_geocodes.csv`. I considered batch processing, but a bug affected only the second batch. I found that it was more efficient to submit all addresses in a single request since it stayed within the 10,000 limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "35c31730-f1b6-4f81-b7bc-c18d1cd44239",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100  104k    0     0  100  104k      0  83603  0:00:01  0:00:01 --:--:-- 83680\n",
      "100  104k    0     0  100  104k      0  46997  0:00:02  0:00:02 --:--:-- 47026\n",
      "100  104k    0     0  100  104k      0  32575  0:00:03  0:00:03 --:--:-- 32583\n",
      "100  104k    0     0  100  104k      0  24981  0:00:04  0:00:04 --:--:-- 24985\n",
      "100  104k    0     0  100  104k      0  20226  0:00:05  0:00:05 --:--:-- 20551\n",
      "100  104k    0     0  100  104k      0  17001  0:00:06  0:00:06 --:--:--     0\n",
      "100  104k    0     0  100  104k      0  14675  0:00:07  0:00:07 --:--:--     0\n",
      "100  104k    0     0  100  104k      0  12895  0:00:08  0:00:08 --:--:--     0\n",
      "100  104k    0     0  100  104k      0  11506  0:00:09  0:00:09 --:--:--     0\n",
      "100  104k    0     0  100  104k      0  10379  0:00:10  0:00:10 --:--:--     0\n",
      "100  104k    0     0  100  104k      0   9454  0:00:11  0:00:11 --:--:--     0\n",
      "100  104k    0     0  100  104k      0   8683  0:00:12  0:00:12 --:--:--     0\n",
      "100  104k    0     0  100  104k      0   8032  0:00:13  0:00:13 --:--:--     0\n",
      "100  104k    0     0  100  104k      0   7472  0:00:14  0:00:14 --:--:--     0\n",
      "100  104k    0     0  100  104k      0   6981  0:00:15  0:00:15 --:--:--     0\n",
      "100  104k    0     0  100  104k      0   6549  0:00:16  0:00:16 --:--:--     0\n",
      "100  104k    0     0  100  104k      0   6167  0:00:17  0:00:17 --:--:--     0\n",
      "100  104k    0     0  100  104k      0   5828  0:00:18  0:00:18 --:--:--     0\n",
      "100  104k    0     0  100  104k      0   5524  0:00:19  0:00:19 --:--:--     0\n",
      "100  104k    0     0  100  104k      0   5254  0:00:20  0:00:20 --:--:--     0\n",
      "100  104k    0     0  100  104k      0   5006  0:00:21  0:00:21 --:--:--     0\n",
      "100  104k    0     0  100  104k      0   4780  0:00:22  0:00:22 --:--:--     0\n",
      "100  104k    0     0  100  104k      0   4574  0:00:23  0:00:23 --:--:--     0\n",
      "100  104k    0     0  100  104k      0   4385  0:00:24  0:00:24 --:--:--     0\n",
      "100  104k    0     0  100  104k      0   4211  0:00:25  0:00:25 --:--:--     0\n",
      "100  104k    0     0  100  104k      0   4052  0:00:26  0:00:26 --:--:--     0\n",
      "100  104k    0     0  100  104k      0   3903  0:00:27  0:00:27 --:--:--     0\n",
      "100  104k    0     0  100  104k      0   3765  0:00:28  0:00:28 --:--:--     0\n",
      "100  104k    0     0  100  104k      0   3637  0:00:29  0:00:29 --:--:--     0\n",
      "100  104k    0     0  100  104k      0   3516  0:00:30  0:00:30 --:--:--     0\n",
      "100  104k    0     0  100  104k      0   3403  0:00:31  0:00:31 --:--:--     0\n",
      "100  104k    0     0  100  104k      0   3297  0:00:32  0:00:32 --:--:--     0\n",
      "100  104k    0     0  100  104k      0   3198  0:00:33  0:00:33 --:--:--     0\n",
      "100  104k    0     0  100  104k      0   3105  0:00:34  0:00:34 --:--:--     0\n",
      "100  104k    0     0  100  104k      0   3017  0:00:35  0:00:35 --:--:--     0\n",
      "100  104k    0     0  100  104k      0   2933  0:00:36  0:00:36 --:--:--     0\n",
      "100  104k    0     0  100  104k      0   2854  0:00:37  0:00:37 --:--:--     0\n",
      "100  104k    0     0  100  104k      0   2780  0:00:38  0:00:38 --:--:--     0\n",
      "100  104k    0     0  100  104k      0   2709  0:00:39  0:00:39 --:--:--     0\n",
      "100  104k    0     0  100  104k      0   2642  0:00:40  0:00:40 --:--:--     0\n",
      "100  104k    0     0  100  104k      0   2578  0:00:41  0:00:41 --:--:--     0\n",
      "100  104k    0     0  100  104k      0   2517  0:00:42  0:00:42 --:--:--     0\n",
      "100  104k    0     0  100  104k      0   2458  0:00:43  0:00:43 --:--:--     0\n",
      "100  104k    0     0  100  104k      0   2403  0:00:44  0:00:44 --:--:--     0\n",
      "100  104k    0     0  100  104k      0   2349  0:00:45  0:00:45 --:--:--     0\n",
      "100  104k    0     0  100  104k      0   2298  0:00:46  0:00:46 --:--:--     0\n",
      "100  104k    0     0  100  104k      0   2250  0:00:47  0:00:47 --:--:--     0\n",
      "100  104k    0     0  100  104k      0   2203  0:00:48  0:00:48 --:--:--     0\n",
      "100  104k    0     0  100  104k      0   2159  0:00:49  0:00:49 --:--:--     0\n",
      "100  104k    0     0  100  104k      0   2115  0:00:50  0:00:50 --:--:--     0\n",
      "100  104k    0     0  100  104k      0   2075  0:00:51  0:00:51 --:--:--     0\n",
      "100  104k    0     0  100  104k      0   2035  0:00:52  0:00:52 --:--:--     0\n",
      "100  104k    0     0  100  104k      0   1996  0:00:53  0:00:53 --:--:--     0\n",
      "100  104k    0     0  100  104k      0   1960  0:00:54  0:00:54 --:--:--     0\n",
      "100  104k    0     0  100  104k      0   1924  0:00:55  0:00:55 --:--:--     0\n",
      "100  104k    0     0  100  104k      0   1890  0:00:56  0:00:56 --:--:--     0\n",
      "100  104k    0     0  100  104k      0   1857  0:00:57  0:00:57 --:--:--     0\n",
      "100  104k    0     0  100  104k      0   1825  0:00:58  0:00:58 --:--:--     0\n",
      "100  104k    0     0  100  104k      0   1795  0:00:59  0:00:59 --:--:--     0\n",
      "100  104k    0     0  100  104k      0   1765  0:01:00  0:01:00 --:--:--     0\n",
      "100  104k    0     0  100  104k      0   1736  0:01:01  0:01:01 --:--:--     0\n",
      "100  104k    0     0  100  104k      0   1708  0:01:02  0:01:02 --:--:--     0\n",
      "100  104k    0     0  100  104k      0   1681  0:01:03  0:01:03 --:--:--     0\n",
      "100  104k    0     0  100  104k      0   1655  0:01:04  0:01:04 --:--:--     0\n",
      "100  104k    0     0  100  104k      0   1630  0:01:05  0:01:05 --:--:--     0\n",
      "100  104k    0     0  100  104k      0   1605  0:01:06  0:01:06 --:--:--     0\n",
      "100  104k    0     0  100  104k      0   1581  0:01:07  0:01:07 --:--:--     0\n",
      "100  104k    0     0  100  104k      0   1558  0:01:08  0:01:08 --:--:--     0\n",
      "100  104k    0     0  100  104k      0   1536  0:01:09  0:01:09 --:--:--     0\n",
      "100  104k    0     0  100  104k      0   1514  0:01:10  0:01:10 --:--:--     0\n",
      "100  104k    0     0  100  104k      0   1508  0:01:11  0:01:11 --:--:--     0\n",
      "100  251k  100  146k  100  104k   2103   1500  0:01:11  0:01:11 --:--:-- 41144\n"
     ]
    }
   ],
   "source": [
    "# I initially submit a batch request using strictly python, but found that there were some formatting issues. I could have\n",
    "# fixed those issues, but chose to use curl instead since it largely formatted the response correctly. I also considered processing \n",
    "# the addresses in batches, but ran into formatting issues for only batch 2. It was a very odd bug, so I chose instead to just submit all addresses\n",
    "# at once since they did not exceed the limit of 10000, and all followed the same format\n",
    "!curl --form addressFile=@addresses.csv --form benchmark=4 --form vintage=4 \\\n",
    "https://geocoding.geo.census.gov/geocoder/geographies/addressbatch --output all_geocodes.csv\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f8e3ff-4d08-4e9b-b218-16fc3570914d",
   "metadata": {},
   "source": [
    "## Part 8: Add headers to the geocodes\n",
    "\n",
    "The raw geocoding results are read from `all_geocodes.csv`. The batch API response does not include headers, so I inferred custom headers using the JSON geocodes response, and saved the data with headers as `all_geocodes_with_headers.csv`. Only columns that will be used to identify census information will be defined, with `\"STATE\"`, `\"COUNTY\"`, and `\"TRACT\"`. I used uppercase for consistency. Unnecessary or ambiguous columns were left unnamed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66ca839a-71d0-41af-a911-726749a0b859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headers added successfully. Saved as all_geocodes_headers.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>??</th>\n",
       "      <th>Original Address</th>\n",
       "      <th>Match Status</th>\n",
       "      <th>Match Type</th>\n",
       "      <th>Matched Address</th>\n",
       "      <th>Longitude/Latitude</th>\n",
       "      <th>TigerLineId</th>\n",
       "      <th>Side of Street</th>\n",
       "      <th>STATE</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>TRACT</th>\n",
       "      <th>??</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>488.0</td>\n",
       "      <td>1116 Winburn Dr, Lexington, KY, 40511</td>\n",
       "      <td>Match</td>\n",
       "      <td>Exact</td>\n",
       "      <td>1116 WINBURN DR, LEXINGTON, KY, 40511</td>\n",
       "      <td>-84.47598578654924,38.089438386187396</td>\n",
       "      <td>31945598.0</td>\n",
       "      <td>R</td>\n",
       "      <td>21.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>3804.0</td>\n",
       "      <td>2003.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1833.0</td>\n",
       "      <td>3101 Richmond Rd, Lexington, KY, 40509</td>\n",
       "      <td>No_Match</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9744.0</td>\n",
       "      <td>2688 Pink Pigeon Pkwy, Lexington, KY, 40509</td>\n",
       "      <td>Match</td>\n",
       "      <td>Exact</td>\n",
       "      <td>2688 PINK PIGEON PKWY, LEXINGTON, KY, 40509</td>\n",
       "      <td>-84.42639655840867,38.02245148652963</td>\n",
       "      <td>31954114.0</td>\n",
       "      <td>R</td>\n",
       "      <td>21.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>3908.0</td>\n",
       "      <td>4040.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29912.0</td>\n",
       "      <td>222 Rosemont Gdn, Lexington, KY, 40503</td>\n",
       "      <td>Match</td>\n",
       "      <td>Exact</td>\n",
       "      <td>222 ROSEMONT GARDEN, LEXINGTON, KY, 40503</td>\n",
       "      <td>-84.5221953519258,38.019400865010994</td>\n",
       "      <td>31922565.0</td>\n",
       "      <td>L</td>\n",
       "      <td>21.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2800.0</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1121.0</td>\n",
       "      <td>2300 Versailles Rd, Lexington, KY, 40504</td>\n",
       "      <td>Match</td>\n",
       "      <td>Exact</td>\n",
       "      <td>2300 VERSAILLES RD, LEXINGTON, KY, 40504</td>\n",
       "      <td>-84.55198240375927,38.046673831061355</td>\n",
       "      <td>31951790.0</td>\n",
       "      <td>R</td>\n",
       "      <td>21.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>5011.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ??                             Original Address Match Status  \\\n",
       "0    488.0        1116 Winburn Dr, Lexington, KY, 40511        Match   \n",
       "1   1833.0       3101 Richmond Rd, Lexington, KY, 40509     No_Match   \n",
       "2   9744.0  2688 Pink Pigeon Pkwy, Lexington, KY, 40509        Match   \n",
       "3  29912.0       222 Rosemont Gdn, Lexington, KY, 40503        Match   \n",
       "4   1121.0     2300 Versailles Rd, Lexington, KY, 40504        Match   \n",
       "\n",
       "  Match Type                              Matched Address  \\\n",
       "0      Exact        1116 WINBURN DR, LEXINGTON, KY, 40511   \n",
       "1        NaN                                          NaN   \n",
       "2      Exact  2688 PINK PIGEON PKWY, LEXINGTON, KY, 40509   \n",
       "3      Exact    222 ROSEMONT GARDEN, LEXINGTON, KY, 40503   \n",
       "4      Exact     2300 VERSAILLES RD, LEXINGTON, KY, 40504   \n",
       "\n",
       "                      Longitude/Latitude  TigerLineId Side of Street  STATE  \\\n",
       "0  -84.47598578654924,38.089438386187396   31945598.0              R   21.0   \n",
       "1                                    NaN          NaN            NaN    NaN   \n",
       "2   -84.42639655840867,38.02245148652963   31954114.0              R   21.0   \n",
       "3   -84.5221953519258,38.019400865010994   31922565.0              L   21.0   \n",
       "4  -84.55198240375927,38.046673831061355   31951790.0              R   21.0   \n",
       "\n",
       "   COUNTY   TRACT      ??  \n",
       "0    67.0  3804.0  2003.0  \n",
       "1     NaN     NaN     NaN  \n",
       "2    67.0  3908.0  4040.0  \n",
       "3    67.0  2800.0  1000.0  \n",
       "4    67.0  3000.0  5011.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# The batch API call did not include headers. Based on the json geocodes, I was able to infer what important columns represented. \n",
    "# Since I only needed tract information, I did not worry about defining ambiguous columns, as they were not necessary for the results. \n",
    "# Coulmns that will be used to identify population in the cencus dataset are formatted in the same manner with \"state\", \"county\", and \"tract\" \n",
    "# columns defined in uppercase\n",
    "headers = [\n",
    "    \"??\", \"Original Address\", \"Match Status\", \"Match Type\", \n",
    "    \"Matched Address\", \"Longitude/Latitude\", \"TigerLineId\", \"Side of Street\", \n",
    "   \"STATE\" , \"COUNTY\", \"TRACT\", \"??\"\n",
    "]\n",
    "\n",
    "\n",
    "# The previously created geocodes CSV is read as a data frame\n",
    "all_geocodes = pd.read_csv(\"all_geocodes.csv\", header=None)\n",
    "\n",
    "# The custom headers are added to the all_geocodes dataframe\n",
    "all_geocodes.columns = headers\n",
    "all_geocodes.columns = headers\n",
    "\n",
    "\n",
    "# A new csv file with the geocodes and headers is saved\n",
    "all_geocodes.to_csv(\"all_geocodes_with_headers.csv\", index=False)\n",
    "\n",
    "\n",
    "print(\"Headers added successfully. Saved as all_geocodes_headers.csv\")\n",
    "all_geocodes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00df8eb-2076-46e8-9d6c-d8aabeff89ef",
   "metadata": {},
   "source": [
    "### determine if an api call  was successful when using imputed Site IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b9ef7d1-975a-452b-875e-2823e96d13bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>??</th>\n",
       "      <th>Original Address</th>\n",
       "      <th>Match Status</th>\n",
       "      <th>Match Type</th>\n",
       "      <th>Matched Address</th>\n",
       "      <th>Longitude/Latitude</th>\n",
       "      <th>TigerLineId</th>\n",
       "      <th>Side of Street</th>\n",
       "      <th>STATE</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>TRACT</th>\n",
       "      <th>??</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>6053.0</td>\n",
       "      <td>2339 Sandersville Rd, Lexington, KY, 40511</td>\n",
       "      <td>Match</td>\n",
       "      <td>Exact</td>\n",
       "      <td>2339 SANDERSVILLE RD, LEXINGTON, KY, 40511</td>\n",
       "      <td>-84.52537550469839,38.08680164496241</td>\n",
       "      <td>636246750.0</td>\n",
       "      <td>R</td>\n",
       "      <td>21.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>3704.0</td>\n",
       "      <td>2031.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ??                            Original Address Match Status  \\\n",
       "52  6053.0  2339 Sandersville Rd, Lexington, KY, 40511        Match   \n",
       "\n",
       "   Match Type                             Matched Address  \\\n",
       "52      Exact  2339 SANDERSVILLE RD, LEXINGTON, KY, 40511   \n",
       "\n",
       "                      Longitude/Latitude  TigerLineId Side of Street  STATE  \\\n",
       "52  -84.52537550469839,38.08680164496241  636246750.0              R   21.0   \n",
       "\n",
       "    COUNTY   TRACT      ??  \n",
       "52    67.0  3704.0  2031.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check to determine if an api call using addresses with imputed Site IDs was successful\n",
    "all_geocodes.loc[all_geocodes['Original Address'].str.contains('2339 Sandersville Rd', na=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104d387e-faa2-42d6-a039-fdda73e14636",
   "metadata": {},
   "source": [
    "## Part 9: Merge Datasets\n",
    "\n",
    "Geocoding data is processed and merged with license information. Only essential columns, are retained including `Original Address`, `STATE`, `COUNTY`, and `TRACT`. It separates the `Original Address` into `street`, `city`, `state`, and `zip` columns while ensuring compatibility with the license data by parsing in reverse (starting with zip and ending with street) limiting the split to the last three commas. Rows with missing `TRACT` values are removed to reduce the chances of potential result skewing. Both the geocoding and license datasets are standardized to lowercase and whitespace-trimmed to ensure consistency for merging. The geocoding information is merged with the license data using shared address columns. Each address is associated with the correct license by merging on shared address columns. The combined dataset is saved as `licenses_w_tract.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f064eb86-7e0d-41dc-9c1a-176f73570965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original Address</th>\n",
       "      <th>STATE</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>TRACT</th>\n",
       "      <th>street</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zip</th>\n",
       "      <th>LicenseType</th>\n",
       "      <th>Status</th>\n",
       "      <th>EffectiveDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1116 Winburn Dr, Lexington, KY, 40511</td>\n",
       "      <td>21.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>3804</td>\n",
       "      <td>1116 winburn dr</td>\n",
       "      <td>lexington</td>\n",
       "      <td>ky</td>\n",
       "      <td>40511</td>\n",
       "      <td>NQ Retail Malt Beverage Package License</td>\n",
       "      <td>Active</td>\n",
       "      <td>10/08/2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2688 Pink Pigeon Pkwy, Lexington, KY, 40509</td>\n",
       "      <td>21.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>3908</td>\n",
       "      <td>2688 pink pigeon pkwy</td>\n",
       "      <td>lexington</td>\n",
       "      <td>ky</td>\n",
       "      <td>40509</td>\n",
       "      <td>NQ Retail Malt Beverage Package License</td>\n",
       "      <td>Active</td>\n",
       "      <td>10/11/2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2688 Pink Pigeon Pkwy, Lexington, KY, 40509</td>\n",
       "      <td>21.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>3908</td>\n",
       "      <td>2688 pink pigeon pkwy</td>\n",
       "      <td>lexington</td>\n",
       "      <td>ky</td>\n",
       "      <td>40509</td>\n",
       "      <td>NQ4 Retail Malt Beverage Drink License</td>\n",
       "      <td>Active</td>\n",
       "      <td>05/27/2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>222 Rosemont Gdn, Lexington, KY, 40503</td>\n",
       "      <td>21.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2800</td>\n",
       "      <td>222 rosemont gdn</td>\n",
       "      <td>lexington</td>\n",
       "      <td>ky</td>\n",
       "      <td>40503</td>\n",
       "      <td>NQ2 Retail Drink License</td>\n",
       "      <td>Active</td>\n",
       "      <td>05/03/2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>222 Rosemont Gdn, Lexington, KY, 40503</td>\n",
       "      <td>21.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2800</td>\n",
       "      <td>222 rosemont gdn</td>\n",
       "      <td>lexington</td>\n",
       "      <td>ky</td>\n",
       "      <td>40503</td>\n",
       "      <td>Special Sunday Retail Drink License</td>\n",
       "      <td>Active</td>\n",
       "      <td>05/03/2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Original Address  STATE  COUNTY  TRACT  \\\n",
       "0        1116 Winburn Dr, Lexington, KY, 40511   21.0    67.0   3804   \n",
       "1  2688 Pink Pigeon Pkwy, Lexington, KY, 40509   21.0    67.0   3908   \n",
       "2  2688 Pink Pigeon Pkwy, Lexington, KY, 40509   21.0    67.0   3908   \n",
       "3       222 Rosemont Gdn, Lexington, KY, 40503   21.0    67.0   2800   \n",
       "4       222 Rosemont Gdn, Lexington, KY, 40503   21.0    67.0   2800   \n",
       "\n",
       "                  street       city state    zip  \\\n",
       "0        1116 winburn dr  lexington    ky  40511   \n",
       "1  2688 pink pigeon pkwy  lexington    ky  40509   \n",
       "2  2688 pink pigeon pkwy  lexington    ky  40509   \n",
       "3       222 rosemont gdn  lexington    ky  40503   \n",
       "4       222 rosemont gdn  lexington    ky  40503   \n",
       "\n",
       "                               LicenseType  Status EffectiveDate  \n",
       "0  NQ Retail Malt Beverage Package License  Active    10/08/2020  \n",
       "1  NQ Retail Malt Beverage Package License  Active    10/11/2018  \n",
       "2   NQ4 Retail Malt Beverage Drink License  Active    05/27/2015  \n",
       "3                 NQ2 Retail Drink License  Active    05/03/2021  \n",
       "4      Special Sunday Retail Drink License  Active    05/03/2021  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the geocode dataset with headers is loaded from a csv file.\n",
    "geo_w_headers = pd.read_csv('all_geocodes_with_headers.csv', encoding='utf-8')\n",
    "# Only pertinent geocode information will be used. There is no need to include fields like \"Longitude/Latitude\", \"TigerLineId\", etc. \n",
    "# Additionally, there is no need to identify additional columns since we are trying to associate geocoding information with the original addresses. \n",
    "# \"Original Address\" column is kept as reference.\n",
    "select_geo_info = geo_w_headers[['Original Address', 'STATE', 'COUNTY', 'TRACT']].copy()\n",
    "\n",
    "# The original address is split into separate columns for compatibility with the license data. Because there are premises that include commas,\n",
    "# the \"Original Address\" column is separated starting with the zip code and ending with the address. There are only 3 necessary columns that I \n",
    "# will used to identify the appropriate corresponding license. Therefore, I stopped splitting the address after 3 commas\n",
    "select_geo_info[['street', 'city', 'state', 'zip']] = (\n",
    "    select_geo_info['Original Address']\n",
    "    .apply(lambda x: pd.Series(x.rsplit(',', 3)))\n",
    ")\n",
    "\n",
    "# I dropped rows with nan values in the 'TRACT' column, because that indicates that there was no information found in the api. It is not as easy to \n",
    "# be sure that an address/license is associated with the appropriate tract, so I removed values that could skew the results (albeit slightly) \n",
    "select_geo_info = select_geo_info.dropna(subset=['TRACT'])\n",
    "select_geo_info['TRACT'] = pd.to_numeric(select_geo_info['TRACT'], errors='coerce').astype(int)\n",
    "\n",
    "# The license information with imputed SiteIDs is loded \n",
    "license_info = pd.read_csv('active_licenses_IDs.csv', encoding='utf-8')\n",
    "# A dataframe is defined to contain relevant columns. 'street','city','state', and 'zip' will be used to identify the appropriate license/address\n",
    "select_license_info = license_info[['street', 'city', 'state', 'zip', 'LicenseType', 'Status', 'EffectiveDate']].copy()\n",
    "\n",
    "# the formatting of street, city, state, and zip are standardized to match between dataframes\n",
    "select_geo_info[['street', 'city', 'state', 'zip']] = select_geo_info[['street', 'city', 'state', 'zip']].apply(lambda x: x.str.strip().str.lower())\n",
    "select_license_info[['street', 'city', 'state', 'zip']] = select_license_info[['street', 'city', 'state', 'zip']].apply(lambda x: x.str.strip().str.lower())\n",
    "\n",
    "# the dataframes are merged without removing duplicates to keep all addresses intact even if they share a tract\n",
    "merged_data = select_geo_info.merge(select_license_info, on=['street', 'city', 'state', 'zip'], how='left')\n",
    "\n",
    "# the combined data is saved as a CSV\n",
    "merged_data.to_csv(\"licenses_w_tract.csv\", index=False)\n",
    "\n",
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92efd6e4-9127-4a3d-a1ca-41e0693bdef2",
   "metadata": {},
   "source": [
    "## Part 10: Calculate the rate of liquor licenses per capita \n",
    "\n",
    "The number of licenses per tract are calculated by grouping and counting rows based on the `TRACT` column. Census data is read into a DataFrame and retains only the relevant columns: `NAME`, `population`, and `TRACT`. The license counts are merged with the census information, resulting in a new DataFrame that includes both the number of licenses and the population for each tract. The rate of licenses per tract is computed by dividing the license count by the population and multiplying by 1,000, then rounding the result to two decimal places. The dataset is sorted first by the number of licenses per tract and saved as `licenses_per_tract_ordered.csv`. THe dataset is then sorted by the calculated rate and saved as `rate_per_tract_ordered.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc7ace9a-e94a-4ada-8761-75c1347bdbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number of licenses per tract is calculated by grouping and counting rows by tract\n",
    "licenses_per_tract = select_geo_info.groupby('TRACT').size().reset_index(name='license_count')\n",
    "licenses_per_tract\n",
    "\n",
    "# THe census information is read into a dataframe\n",
    "census_info = pd.read_csv('census_output.csv', encoding='utf-8')\n",
    "# Only the \"NAME\", \"population\", and \"tract\" columns are used\n",
    "census_info = census_info[['NAME','population', 'TRACT']].copy()\n",
    "census_info\n",
    "\n",
    "# To view the number of licenses per tract, I have merged each tract's license count into a dataframe containing tract information\n",
    "license_count_per_tract = census_info.merge(licenses_per_tract, on=['TRACT'], how='right')\n",
    "# The rate per tract is calculated and saved into its own column\n",
    "license_count_per_tract['rate'] = (license_count_per_tract['license_count'] / license_count_per_tract['population'] * 1000).round(2)\n",
    "\n",
    "# The dataset is first ordered by number of licenses per tract. The results are saved into a csv file.\n",
    "ordered_by_count = license_count_per_tract.sort_values(by='license_count', ascending=False)\n",
    "ordered_by_count.to_csv(\"licenses_per_tract_ordered.csv\",index=False)\n",
    "\n",
    "# The dataset is ordered by the rate. The results are saved into a csv file\n",
    "ordered_by_rate = ordered_by_count.sort_values(by='rate', ascending=False)\n",
    "ordered_by_rate.to_csv(\"rate_per_tract_ordered.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cff1365-2769-4233-9f67-e5bd2763221b",
   "metadata": {},
   "source": [
    "## Part 11: Show the top 20 neighborhoods with the highest number of licenses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "909351a5-2d85-4f3b-b5e7-a19ca069219a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>population</th>\n",
       "      <th>TRACT</th>\n",
       "      <th>license_count</th>\n",
       "      <th>rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Census Tract 1.01</td>\n",
       "      <td>3171</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>23.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Census Tract 42.04</td>\n",
       "      <td>5577</td>\n",
       "      <td>4204</td>\n",
       "      <td>50</td>\n",
       "      <td>8.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Census Tract 10</td>\n",
       "      <td>1598</td>\n",
       "      <td>1000</td>\n",
       "      <td>35</td>\n",
       "      <td>21.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Census Tract 9</td>\n",
       "      <td>5951</td>\n",
       "      <td>900</td>\n",
       "      <td>33</td>\n",
       "      <td>5.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Census Tract 39.08</td>\n",
       "      <td>5758</td>\n",
       "      <td>3908</td>\n",
       "      <td>25</td>\n",
       "      <td>4.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Census Tract 42.08</td>\n",
       "      <td>7671</td>\n",
       "      <td>4208</td>\n",
       "      <td>25</td>\n",
       "      <td>3.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Census Tract 28</td>\n",
       "      <td>4028</td>\n",
       "      <td>2800</td>\n",
       "      <td>24</td>\n",
       "      <td>5.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Census Tract 7</td>\n",
       "      <td>2610</td>\n",
       "      <td>700</td>\n",
       "      <td>21</td>\n",
       "      <td>8.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Census Tract 1.02</td>\n",
       "      <td>1584</td>\n",
       "      <td>102</td>\n",
       "      <td>21</td>\n",
       "      <td>13.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Census Tract 27</td>\n",
       "      <td>3858</td>\n",
       "      <td>2700</td>\n",
       "      <td>20</td>\n",
       "      <td>5.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Census Tract 39.06</td>\n",
       "      <td>5425</td>\n",
       "      <td>3906</td>\n",
       "      <td>17</td>\n",
       "      <td>3.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Census Tract 13</td>\n",
       "      <td>2131</td>\n",
       "      <td>1300</td>\n",
       "      <td>15</td>\n",
       "      <td>7.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Census Tract 37.04</td>\n",
       "      <td>6316</td>\n",
       "      <td>3704</td>\n",
       "      <td>15</td>\n",
       "      <td>2.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Census Tract 18</td>\n",
       "      <td>2907</td>\n",
       "      <td>1800</td>\n",
       "      <td>15</td>\n",
       "      <td>5.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Census Tract 38.04</td>\n",
       "      <td>6410</td>\n",
       "      <td>3804</td>\n",
       "      <td>14</td>\n",
       "      <td>2.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Census Tract 5</td>\n",
       "      <td>3411</td>\n",
       "      <td>500</td>\n",
       "      <td>14</td>\n",
       "      <td>4.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Census Tract 3</td>\n",
       "      <td>2472</td>\n",
       "      <td>300</td>\n",
       "      <td>13</td>\n",
       "      <td>5.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Census Tract 32.02</td>\n",
       "      <td>6532</td>\n",
       "      <td>3202</td>\n",
       "      <td>13</td>\n",
       "      <td>1.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Census Tract 34.02</td>\n",
       "      <td>4511</td>\n",
       "      <td>3402</td>\n",
       "      <td>13</td>\n",
       "      <td>2.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Census Tract 42.07</td>\n",
       "      <td>3531</td>\n",
       "      <td>4207</td>\n",
       "      <td>12</td>\n",
       "      <td>3.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  NAME  population  TRACT  license_count   rate\n",
       "0    Census Tract 1.01        3171    101             76  23.97\n",
       "71  Census Tract 42.04        5577   4204             50   8.97\n",
       "11     Census Tract 10        1598   1000             35  21.90\n",
       "10      Census Tract 9        5951    900             33   5.55\n",
       "52  Census Tract 39.08        5758   3908             25   4.34\n",
       "73  Census Tract 42.08        7671   4208             25   3.26\n",
       "28     Census Tract 28        4028   2800             24   5.96\n",
       "7       Census Tract 7        2610    700             21   8.05\n",
       "1    Census Tract 1.02        1584    102             21  13.26\n",
       "27     Census Tract 27        3858   2700             20   5.18\n",
       "51  Census Tract 39.06        5425   3906             17   3.13\n",
       "13     Census Tract 13        2131   1300             15   7.04\n",
       "47  Census Tract 37.04        6316   3704             15   2.37\n",
       "18     Census Tract 18        2907   1800             15   5.16\n",
       "50  Census Tract 38.04        6410   3804             14   2.18\n",
       "5       Census Tract 5        3411    500             14   4.10\n",
       "3       Census Tract 3        2472    300             13   5.26\n",
       "33  Census Tract 32.02        6532   3202             13   1.99\n",
       "35  Census Tract 34.02        4511   3402             13   2.88\n",
       "72  Census Tract 42.07        3531   4207             12   3.40"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordered_by_count.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100fb9f2-597f-4cf5-abb4-255ff8b7df37",
   "metadata": {},
   "source": [
    "## Part 12: Show the top 20 neighborhoods with the highest rate of alcohol availability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "0ead9e87-cf60-412a-a614-dc5097a5e95d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>population</th>\n",
       "      <th>TRACT</th>\n",
       "      <th>license_count</th>\n",
       "      <th>rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Census Tract 1.01</td>\n",
       "      <td>3171</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>23.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Census Tract 10</td>\n",
       "      <td>1598</td>\n",
       "      <td>1000</td>\n",
       "      <td>35</td>\n",
       "      <td>21.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Census Tract 1.02</td>\n",
       "      <td>1584</td>\n",
       "      <td>102</td>\n",
       "      <td>21</td>\n",
       "      <td>13.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Census Tract 42.04</td>\n",
       "      <td>5577</td>\n",
       "      <td>4204</td>\n",
       "      <td>50</td>\n",
       "      <td>8.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Census Tract 7</td>\n",
       "      <td>2610</td>\n",
       "      <td>700</td>\n",
       "      <td>21</td>\n",
       "      <td>8.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Census Tract 13</td>\n",
       "      <td>2131</td>\n",
       "      <td>1300</td>\n",
       "      <td>15</td>\n",
       "      <td>7.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Census Tract 28</td>\n",
       "      <td>4028</td>\n",
       "      <td>2800</td>\n",
       "      <td>24</td>\n",
       "      <td>5.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Census Tract 38.02</td>\n",
       "      <td>1926</td>\n",
       "      <td>3802</td>\n",
       "      <td>11</td>\n",
       "      <td>5.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Census Tract 9</td>\n",
       "      <td>5951</td>\n",
       "      <td>900</td>\n",
       "      <td>33</td>\n",
       "      <td>5.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Census Tract 3</td>\n",
       "      <td>2472</td>\n",
       "      <td>300</td>\n",
       "      <td>13</td>\n",
       "      <td>5.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Census Tract 27</td>\n",
       "      <td>3858</td>\n",
       "      <td>2700</td>\n",
       "      <td>20</td>\n",
       "      <td>5.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Census Tract 16</td>\n",
       "      <td>2322</td>\n",
       "      <td>1600</td>\n",
       "      <td>12</td>\n",
       "      <td>5.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Census Tract 18</td>\n",
       "      <td>2907</td>\n",
       "      <td>1800</td>\n",
       "      <td>15</td>\n",
       "      <td>5.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Census Tract 40.07</td>\n",
       "      <td>1977</td>\n",
       "      <td>4007</td>\n",
       "      <td>10</td>\n",
       "      <td>5.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Census Tract 39.10</td>\n",
       "      <td>2541</td>\n",
       "      <td>3910</td>\n",
       "      <td>12</td>\n",
       "      <td>4.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Census Tract 39.08</td>\n",
       "      <td>5758</td>\n",
       "      <td>3908</td>\n",
       "      <td>25</td>\n",
       "      <td>4.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Census Tract 22</td>\n",
       "      <td>1703</td>\n",
       "      <td>2200</td>\n",
       "      <td>7</td>\n",
       "      <td>4.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Census Tract 5</td>\n",
       "      <td>3411</td>\n",
       "      <td>500</td>\n",
       "      <td>14</td>\n",
       "      <td>4.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Census Tract 15</td>\n",
       "      <td>2316</td>\n",
       "      <td>1500</td>\n",
       "      <td>8</td>\n",
       "      <td>3.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Census Tract 42.07</td>\n",
       "      <td>3531</td>\n",
       "      <td>4207</td>\n",
       "      <td>12</td>\n",
       "      <td>3.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  NAME  population  TRACT  license_count   rate\n",
       "0    Census Tract 1.01        3171    101             76  23.97\n",
       "11     Census Tract 10        1598   1000             35  21.90\n",
       "1    Census Tract 1.02        1584    102             21  13.26\n",
       "71  Census Tract 42.04        5577   4204             50   8.97\n",
       "7       Census Tract 7        2610    700             21   8.05\n",
       "13     Census Tract 13        2131   1300             15   7.04\n",
       "28     Census Tract 28        4028   2800             24   5.96\n",
       "48  Census Tract 38.02        1926   3802             11   5.71\n",
       "10      Census Tract 9        5951    900             33   5.55\n",
       "3       Census Tract 3        2472    300             13   5.26\n",
       "27     Census Tract 27        3858   2700             20   5.18\n",
       "16     Census Tract 16        2322   1600             12   5.17\n",
       "18     Census Tract 18        2907   1800             15   5.16\n",
       "65  Census Tract 40.07        1977   4007             10   5.06\n",
       "54  Census Tract 39.10        2541   3910             12   4.72\n",
       "52  Census Tract 39.08        5758   3908             25   4.34\n",
       "22     Census Tract 22        1703   2200              7   4.11\n",
       "5       Census Tract 5        3411    500             14   4.10\n",
       "15     Census Tract 15        2316   1500              8   3.45\n",
       "72  Census Tract 42.07        3531   4207             12   3.40"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordered_by_rate.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdbe7e5-b273-46d3-9ab3-7415204cb0ea",
   "metadata": {},
   "source": [
    "## Part 13: Discussion on whether or not these two top-20 lists differ and how\n",
    "There appears to be some overlap between the top 20 census tracts based on license count and rate. There are some differences in ranking but the common entries are tracts that rank high in both license count and rate. There seem to be certain locations that have both a significant number of licenses and a high rate per population. Tracts with high rates despite having fewer licenses appear to have smaller populations that drive the rate up. Likewise, some tracts with high license counts but lower ranking rates have larger populations. Overall a basic yet interesting look at Alchohol availability in Fayette county. In the future I'd like to expand this study and delve deeper into some additional statistics that incorporate rate of crime and domestic violence."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
